{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Copy of Load_Data_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bm8pBDJ2fOG",
        "colab_type": "code",
        "outputId": "e08bfda9-c10e-45a1-c9c2-c6256ba52b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Mounts drive to access google drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bheXfQKvA_Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets us save models to drive\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajaqNbr5BEfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets us save models to drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19MF0efW7qeU",
        "colab_type": "code",
        "outputId": "1ed2c9d8-f3a9-49a8-a834-34b2c24d1fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "import datetime, os\n",
        "print(tensorflow.__version__)\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCeeBw5AdjOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Launches TensroBoard\n",
        "!kill 369\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKKFeNYBwYmT",
        "colab_type": "code",
        "outputId": "518af829-f25f-4d95-bcb8-67f2fce1e2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#CNN Optimized\n",
        "#Must restart runtime after each run\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import time\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "import pickle\n",
        "\n",
        "pickle_in = open(\"/content/drive/My Drive/Science Fair/Malaria Project/X.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/My Drive/Science Fair/Malaria Project/y.pickle\",\"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X = X/255.0\n",
        "\n",
        "dense_layers = [1, 2, 3, 4]\n",
        "layer_sizes = [64, 128, 256]\n",
        "conv_layers = [1, 2, 3]\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
        "            print(NAME)\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size, (3, 3)))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            for l in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "            model.add(Dense(1))\n",
        "            model.add(Activation('sigmoid'))\n",
        "\n",
        "            model.compile(loss='binary_crossentropy',\n",
        "                          optimizer='adam',\n",
        "                          metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "            model.fit(X, y, batch_size=batch_size, epochs=26, validation_split=0.3, callbacks=[tensorboard])\n",
        "            \n",
        "           #Saving final model\n",
        "            model.save('Final_Optimized_Model.h5')\n",
        "            model_file = drive.CreateFile({'title' : 'Final_Optimized_Model.h5'})\n",
        "            model_file.SetContentFile('Final_Optimized_Model.h5')\n",
        "            model_file.Upload()\n",
        "            drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3-conv-128-nodes-1-dense-1577933599\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 19290 samples, validate on 8268 samples\n",
            "Epoch 1/26\n",
            "19290/19290 [==============================] - 10s 496us/sample - loss: 0.6919 - acc: 0.5240 - precision: 0.5239 - recall: 0.4585 - val_loss: 0.6835 - val_acc: 0.6274 - val_precision: 0.7058 - val_recall: 0.4553\n",
            "Epoch 2/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.6632 - acc: 0.6304 - precision: 0.6614 - recall: 0.5249 - val_loss: 0.7276 - val_acc: 0.4950 - val_precision: 1.0000 - val_recall: 0.0048\n",
            "Epoch 3/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.6100 - acc: 0.6723 - precision: 0.6726 - recall: 0.6635 - val_loss: 0.5719 - val_acc: 0.6836 - val_precision: 0.6223 - val_recall: 0.9573\n",
            "Epoch 4/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.5297 - acc: 0.7272 - precision: 0.6982 - recall: 0.7942 - val_loss: 0.4682 - val_acc: 0.7654 - val_precision: 0.7071 - val_recall: 0.9178\n",
            "Epoch 5/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.4211 - acc: 0.8097 - precision: 0.7723 - recall: 0.8749 - val_loss: 0.3548 - val_acc: 0.8426 - val_precision: 0.7935 - val_recall: 0.9325\n",
            "Epoch 6/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.3174 - acc: 0.8665 - precision: 0.8290 - recall: 0.9213 - val_loss: 0.2841 - val_acc: 0.8774 - val_precision: 0.8303 - val_recall: 0.9530\n",
            "Epoch 7/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.2497 - acc: 0.9002 - precision: 0.8687 - recall: 0.9415 - val_loss: 0.2435 - val_acc: 0.9002 - val_precision: 0.8541 - val_recall: 0.9688\n",
            "Epoch 8/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.2199 - acc: 0.9140 - precision: 0.8857 - recall: 0.9495 - val_loss: 0.2244 - val_acc: 0.9097 - val_precision: 0.8695 - val_recall: 0.9671\n",
            "Epoch 9/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.2033 - acc: 0.9227 - precision: 0.8974 - recall: 0.9533 - val_loss: 0.2172 - val_acc: 0.9153 - val_precision: 0.8752 - val_recall: 0.9716\n",
            "Epoch 10/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1873 - acc: 0.9287 - precision: 0.9070 - recall: 0.9543 - val_loss: 0.1897 - val_acc: 0.9303 - val_precision: 0.9100 - val_recall: 0.9573\n",
            "Epoch 11/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1741 - acc: 0.9340 - precision: 0.9157 - recall: 0.9551 - val_loss: 0.2015 - val_acc: 0.9250 - val_precision: 0.9348 - val_recall: 0.9161\n",
            "Epoch 12/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1751 - acc: 0.9342 - precision: 0.9175 - recall: 0.9533 - val_loss: 0.1820 - val_acc: 0.9325 - val_precision: 0.9091 - val_recall: 0.9633\n",
            "Epoch 13/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1637 - acc: 0.9382 - precision: 0.9234 - recall: 0.9547 - val_loss: 0.1710 - val_acc: 0.9377 - val_precision: 0.9259 - val_recall: 0.9535\n",
            "Epoch 14/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1556 - acc: 0.9417 - precision: 0.9283 - recall: 0.9565 - val_loss: 0.1701 - val_acc: 0.9390 - val_precision: 0.9205 - val_recall: 0.9631\n",
            "Epoch 15/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1494 - acc: 0.9445 - precision: 0.9323 - recall: 0.9578 - val_loss: 0.1636 - val_acc: 0.9389 - val_precision: 0.9309 - val_recall: 0.9502\n",
            "Epoch 16/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1463 - acc: 0.9446 - precision: 0.9355 - recall: 0.9544 - val_loss: 0.1820 - val_acc: 0.9337 - val_precision: 0.9030 - val_recall: 0.9740\n",
            "Epoch 17/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1405 - acc: 0.9478 - precision: 0.9389 - recall: 0.9573 - val_loss: 0.1615 - val_acc: 0.9427 - val_precision: 0.9253 - val_recall: 0.9650\n",
            "Epoch 18/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.1326 - acc: 0.9521 - precision: 0.9428 - recall: 0.9619 - val_loss: 0.1561 - val_acc: 0.9413 - val_precision: 0.9363 - val_recall: 0.9490\n",
            "Epoch 19/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1259 - acc: 0.9542 - precision: 0.9492 - recall: 0.9592 - val_loss: 0.1854 - val_acc: 0.9334 - val_precision: 0.8996 - val_recall: 0.9778\n",
            "Epoch 20/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1380 - acc: 0.9504 - precision: 0.9410 - recall: 0.9605 - val_loss: 0.1801 - val_acc: 0.9393 - val_precision: 0.9141 - val_recall: 0.9716\n",
            "Epoch 21/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1300 - acc: 0.9532 - precision: 0.9458 - recall: 0.9609 - val_loss: 0.1595 - val_acc: 0.9405 - val_precision: 0.9491 - val_recall: 0.9328\n",
            "Epoch 22/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1123 - acc: 0.9604 - precision: 0.9564 - recall: 0.9642 - val_loss: 0.1617 - val_acc: 0.9452 - val_precision: 0.9262 - val_recall: 0.9692\n",
            "Epoch 23/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1056 - acc: 0.9624 - precision: 0.9576 - recall: 0.9670 - val_loss: 0.1647 - val_acc: 0.9387 - val_precision: 0.9535 - val_recall: 0.9242\n",
            "Epoch 24/26\n",
            "19290/19290 [==============================] - 2s 120us/sample - loss: 0.1066 - acc: 0.9625 - precision: 0.9566 - recall: 0.9684 - val_loss: 0.1571 - val_acc: 0.9434 - val_precision: 0.9457 - val_recall: 0.9426\n",
            "Epoch 25/26\n",
            "19290/19290 [==============================] - 2s 122us/sample - loss: 0.0961 - acc: 0.9667 - precision: 0.9635 - recall: 0.9697 - val_loss: 0.1588 - val_acc: 0.9456 - val_precision: 0.9261 - val_recall: 0.9702\n",
            "Epoch 26/26\n",
            "19290/19290 [==============================] - 2s 121us/sample - loss: 0.0923 - acc: 0.9682 - precision: 0.9644 - recall: 0.9718 - val_loss: 0.1633 - val_acc: 0.9458 - val_precision: 0.9310 - val_recall: 0.9647\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}